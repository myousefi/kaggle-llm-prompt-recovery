{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Connected to kaggle_llm (Python 3.11.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files not modified in the last 24 hours:\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344663.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344954.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344955.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344956.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344957.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344958.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344967.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344976.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41345667.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346663.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346664.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346665.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346666.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346667.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346677.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346685.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348217.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348561.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348562.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348563.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348564.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348565.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348578.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348590.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350401.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350634.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350635.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350636.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350637.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350638.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350651.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350652.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351621.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351756.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351761.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351762.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351764.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351771.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351772.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351773.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352347.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352488.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352494.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352495.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352496.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352499.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352500.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352501.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353061.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353193.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353197.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353198.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353199.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353202.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353203.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353204.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353583.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353782.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353788.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353789.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353790.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353797.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353798.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353799.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354283.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354398.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354403.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354404.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354405.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354411.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354412.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354413.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41356430.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357236.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357241.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357242.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357243.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357247.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357248.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357249.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41358842.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41358999.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359014.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359015.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359016.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359022.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359023.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359024.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41360143.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361137.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361138.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361139.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361168.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361198.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361199.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361200.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362090.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362308.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362309.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362310.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362351.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362460.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362461.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362462.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41363904.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364310.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364311.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364312.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364378.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364400.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364401.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364402.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364889.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372403.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372404.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372408.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372409.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372429.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372454.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373630.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373631.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373650.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373651.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373708.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373784.json\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Get the current time\n",
    "now = datetime.now()\n",
    "\n",
    "# Calculate the time 24 hours ago from the current time\n",
    "twenty_four_hours_ago = now  # - timedelta(hours=24)\n",
    "\n",
    "# Pattern to match the files with varying numbers in the file path\n",
    "file_pattern1 = \"/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/gemma_7b_it_rewrites_*.json\"\n",
    "file_pattern2 = \"/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_*.json\"\n",
    "\n",
    "# Use glob to find all file paths that match the patterns\n",
    "file_paths1 = glob.glob(file_pattern1)\n",
    "file_paths2 = glob.glob(file_pattern2)\n",
    "file_paths = file_paths1 + file_paths2\n",
    "\n",
    "# Filter files that were modified within the last 24 hours\n",
    "recent_file_paths = [\n",
    "    file\n",
    "    for file in file_paths\n",
    "    if datetime.fromtimestamp(os.path.getmtime(file)) < twenty_four_hours_ago\n",
    "]\n",
    "\n",
    "# Output the list of recent file paths\n",
    "print(\"Files not modified in the last 24 hours:\")\n",
    "for file_path in recent_file_paths:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "import re\n",
    "\n",
    "# Initialize an empty list to store the extracted entries\n",
    "entries = []\n",
    "\n",
    "# Iterate over the recent file paths\n",
    "for file_path in recent_file_paths:\n",
    "    # Open the JSON file and load its contents\n",
    "    with open(file_path, \"r\") as file:\n",
    "        file_contents = file.read()\n",
    "        entries_raw = re.findall(r\"\\{.*?\\}\", file_contents, re.DOTALL)\n",
    "        for entry_raw in entries_raw:\n",
    "            try:\n",
    "                entry = json.loads(entry_raw)\n",
    "\n",
    "                if isinstance(entry[\"rewrite_prompt\"], float):\n",
    "                    continue\n",
    "\n",
    "                patterns = [\n",
    "                    r\"^.*?[hH]ere is.*?\\n\\n\",\n",
    "                    r\"^.*?[hH]ere \\'s.*?\\n\\n\",\n",
    "                    r\"^.*?[Ss]ure, here*?\\n\\n\",\n",
    "                ]\n",
    "\n",
    "                filtered = entry[\"rewritten_text\"]\n",
    "                for pattern in patterns:\n",
    "                    filtered = re.sub(pattern, \"\", filtered, flags=re.DOTALL)\n",
    "\n",
    "                extracted_entry = {\n",
    "                    \"rewrite_prompt\": entry[\"rewrite_prompt\"],\n",
    "                    \"original_text\": entry[\"original_text\"],\n",
    "                    # \"rewritten_text\": entry[\"rewritten_text\"],\n",
    "                    \"rewritten_text\": str(filtered),\n",
    "                }\n",
    "                entries.append(extracted_entry)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a HuggingFace Dataset from the extracted entries\n",
    "dataset = Dataset.from_list(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96b3ce3e6c54b539df4cddb0c6d677b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/39114 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aeefb98c1164d7186287eed761115f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/9779 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# Create a DatasetDict from the split datasets\n",
    "dataset_dict = DatasetDict(\n",
    "    {\"train\": train_test_split[\"train\"], \"test\": train_test_split[\"test\"]}\n",
    ")\n",
    "\n",
    "# Save the dataset to a file\n",
    "dataset_dict.save_to_disk(\n",
    "    \"/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/gemini_categorized_prompts/dataset_train_test_split.hf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files not modified in the last 24 hours:\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344663.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344954.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344955.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344956.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344957.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344958.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344967.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344976.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41345667.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346663.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346664.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346665.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346666.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346667.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346677.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346685.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348217.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348561.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348562.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348563.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348564.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348565.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348578.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348590.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350401.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350634.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350635.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350636.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350637.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350638.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350651.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350652.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351621.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351756.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351761.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351762.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351764.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351771.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351772.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351773.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352347.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352488.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352494.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352495.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352496.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352499.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352500.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352501.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353061.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353193.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353197.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353198.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353199.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353202.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353203.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353204.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353583.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353782.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353788.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353789.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353790.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353797.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353798.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353799.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354283.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354398.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354403.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354404.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354405.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354411.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354412.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354413.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41356430.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357236.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357241.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357242.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357243.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357247.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357248.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357249.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41358842.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41358999.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359014.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359015.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359016.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359022.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359023.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359024.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41360143.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361137.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361138.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361139.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361168.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361198.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361199.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361200.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362090.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362308.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362309.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362310.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362351.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362460.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362461.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362462.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41363904.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364310.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364311.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364312.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364378.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364400.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364401.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364402.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364889.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372403.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372404.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372408.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372409.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372429.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372454.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373630.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373631.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373650.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373651.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373708.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373784.json\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Get the current time\n",
    "now = datetime.now()\n",
    "\n",
    "# Calculate the time 24 hours ago from the current time\n",
    "twenty_four_hours_ago = now  # - timedelta(hours=24)\n",
    "\n",
    "# Pattern to match the files with varying numbers in the file path\n",
    "file_pattern1 = \"/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/gemma_7b_it_rewrites_*.json\"\n",
    "file_pattern2 = \"/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_*.json\"\n",
    "\n",
    "# Use glob to find all file paths that match the patterns\n",
    "file_paths1 = glob.glob(file_pattern1)\n",
    "file_paths2 = glob.glob(file_pattern2)\n",
    "file_paths = file_paths1 + file_paths2\n",
    "\n",
    "# Filter files that were modified within the last 24 hours\n",
    "# recent_file_paths = [\n",
    "#     file\n",
    "#     for file in file_paths\n",
    "#     if datetime.fromtimestamp(os.path.getmtime(file)) < twenty_four_hours_ago\n",
    "# ]\n",
    "\n",
    "# Output the list of recent file paths\n",
    "print(\"Files not modified in the last 24 hours:\")\n",
    "for file_path in file_paths:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "import re\n",
    "\n",
    "# Initialize an empty list to store the extracted entries\n",
    "entries = []\n",
    "\n",
    "# Iterate over the recent file paths\n",
    "for file_path in recent_file_paths:\n",
    "    # Open the JSON file and load its contents\n",
    "    with open(file_path, \"r\") as file:\n",
    "        file_contents = file.read()\n",
    "        entries_raw = re.findall(r\"\\{.*?\\}\", file_contents, re.DOTALL)\n",
    "        for entry_raw in entries_raw:\n",
    "            try:\n",
    "                entry = json.loads(entry_raw)\n",
    "\n",
    "                if isinstance(entry[\"rewrite_prompt\"], float):\n",
    "                    continue\n",
    "\n",
    "                patterns = [\n",
    "                    r\"^.*?[hH]ere is.*?\\n\\n\",\n",
    "                    r\"^.*?[hH]ere \\'s.*?\\n\\n\",\n",
    "                    r\"^.*?[Ss]ure, here*?\\n\\n\",\n",
    "                ]\n",
    "\n",
    "                filtered = entry[\"rewritten_text\"]\n",
    "                for pattern in patterns:\n",
    "                    filtered = re.sub(pattern, \"\", filtered, flags=re.DOTALL)\n",
    "\n",
    "                extracted_entry = {\n",
    "                    \"rewrite_prompt\": entry[\"rewrite_prompt\"],\n",
    "                    \"original_text\": entry[\"original_text\"],\n",
    "                    # \"rewritten_text\": entry[\"rewritten_text\"],\n",
    "                    \"rewritten_text\": str(filtered),\n",
    "                }\n",
    "                entries.append(extracted_entry)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a HuggingFace Dataset from the extracted entries\n",
    "dataset = Dataset.from_list(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51b559eda424d60b988b36ff3d4bbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/39114 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1b6d4c95ee42b59d8cb406750a9089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/9779 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# Create a DatasetDict from the split datasets\n",
    "dataset_dict = DatasetDict(\n",
    "    {\"train\": train_test_split[\"train\"], \"test\": train_test_split[\"test\"]}\n",
    ")\n",
    "\n",
    "# Save the dataset to a file\n",
    "dataset_dict.save_to_disk(\n",
    "    \"/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/gemini_categorized_prompts/dataset_train_test_split.hf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files not modified in the last 24 hours:\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344663.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344954.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344955.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344956.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344957.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344958.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344967.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344976.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41345667.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346663.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346664.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346665.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346666.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346667.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346677.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346685.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348217.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348561.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348562.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348563.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348564.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348565.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348578.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348590.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350401.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350634.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350635.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350636.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350637.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350638.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350651.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350652.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351621.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351756.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351761.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351762.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351764.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351771.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351772.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351773.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352347.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352488.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352494.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352495.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352496.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352499.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352500.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352501.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353061.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353193.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353197.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353198.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353199.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353202.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353203.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353204.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353583.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353782.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353788.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353789.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353790.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353797.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353798.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353799.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354283.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354398.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354403.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354404.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354405.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354411.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354412.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354413.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41356430.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357236.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357241.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357242.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357243.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357247.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357248.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357249.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41358842.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41358999.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359014.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359015.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359016.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359022.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359023.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359024.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41360143.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361137.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361138.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361139.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361168.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361198.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361199.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361200.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362090.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362308.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362309.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362310.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362351.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362460.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362461.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362462.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41363904.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364310.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364311.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364312.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364378.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364400.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364401.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364402.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364889.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372403.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372404.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372408.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372409.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372429.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372454.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373630.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373631.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373650.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373651.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373708.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373784.json\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Get the current time\n",
    "now = datetime.now()\n",
    "\n",
    "# Calculate the time 24 hours ago from the current time\n",
    "twenty_four_hours_ago = now  # - timedelta(hours=24)\n",
    "\n",
    "# Pattern to match the files with varying numbers in the file path\n",
    "file_pattern1 = \"/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/gemma_7b_it_rewrites_*.json\"\n",
    "file_pattern2 = \"/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_*.json\"\n",
    "\n",
    "# Use glob to find all file paths that match the patterns\n",
    "file_paths1 = glob.glob(file_pattern1)\n",
    "file_paths2 = glob.glob(file_pattern2)\n",
    "file_paths = file_paths1 + file_paths2\n",
    "\n",
    "# Filter files that were modified within the last 24 hours\n",
    "# recent_file_paths = [\n",
    "#     file\n",
    "#     for file in file_paths\n",
    "#     if datetime.fromtimestamp(os.path.getmtime(file)) < twenty_four_hours_ago\n",
    "# ]\n",
    "\n",
    "# Output the list of recent file paths\n",
    "print(\"Files not modified in the last 24 hours:\")\n",
    "for file_path in file_paths:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "import re\n",
    "\n",
    "# Initialize an empty list to store the extracted entries\n",
    "entries = []\n",
    "\n",
    "# Iterate over the recent file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 6, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/notebooks/02-dataset-generation-for-instruction-tuning.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/gemini_categorized_prompts/prompts.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m )\u001b[39m.\u001b[39mset_index(\u001b[39m\"\u001b[39m\u001b[39mPrompt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m file_path \u001b[39min\u001b[39;00m file_paths:\n\u001b[1;32m      9\u001b[0m     \u001b[39m# Open the JSON file and load its contents\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file_path, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_llm/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_llm/lib/python3.11/site-packages/pandas/io/parsers/readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    616\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 617\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_llm/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1749\u001b[0m         nrows\n\u001b[1;32m   1750\u001b[0m     )\n\u001b[1;32m   1751\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_llm/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:904\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2058\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 6, saw 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/gemini_categorized_prompts/prompts.csv\"\n",
    ").set_index(\"Prompt\")\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # Open the JSON file and load its contents\n",
    "    with open(file_path, \"r\") as file:\n",
    "        file_contents = file.read()\n",
    "        entries_raw = re.findall(r\"\\{.*?\\}\", file_contents, re.DOTALL)\n",
    "        for entry_raw in entries_raw:\n",
    "            try:\n",
    "                entry = json.loads(entry_raw)\n",
    "\n",
    "                if isinstance(entry[\"rewrite_prompt\"], float):\n",
    "                    continue\n",
    "\n",
    "                patterns = [\n",
    "                    r\"^.*?[hH]ere is.*?\\n\\n\",\n",
    "                    r\"^.*?[hH]ere \\'s.*?\\n\\n\",\n",
    "                    r\"^.*?[Ss]ure, here*?\\n\\n\",\n",
    "                ]\n",
    "\n",
    "                filtered = entry[\"rewritten_text\"]\n",
    "                for pattern in patterns:\n",
    "                    filtered = re.sub(pattern, \"\", filtered, flags=re.DOTALL)\n",
    "\n",
    "                extracted_entry = {\n",
    "                    \"rewrite_prompt\": entry[\"rewrite_prompt\"],\n",
    "                    \"original_text\": entry[\"original_text\"],\n",
    "                    \"rewritten_text\": str(filtered),\n",
    "                    \"category\": df.loc[entry[\"rewrite_prompt\"], \"Category\"],\n",
    "                }\n",
    "                entries.append(extracted_entry)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "# Create a HuggingFace Dataset from the extracted entries\n",
    "dataset = Dataset.from_list(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# Create a DatasetDict from the split datasets\n",
    "dataset_dict = DatasetDict(\n",
    "    {\"train\": train_test_split[\"train\"], \"test\": train_test_split[\"test\"]}\n",
    ")\n",
    "\n",
    "# Save the dataset to a file\n",
    "dataset_dict.save_to_disk(\n",
    "    \"/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/gemini_categorized_prompts/dataset_train_test_split.hf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files not modified in the last 24 hours:\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344663.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344954.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344955.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344956.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344957.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344958.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344967.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41344976.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41345667.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346663.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346664.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346665.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346666.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346667.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346677.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41346685.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348217.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348561.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348562.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348563.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348564.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348565.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348578.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41348590.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350401.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350634.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350635.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350636.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350637.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350638.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350651.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41350652.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351621.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351756.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351761.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351762.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351764.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351771.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351772.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41351773.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352347.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352488.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352494.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352495.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352496.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352499.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352500.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41352501.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353061.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353193.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353197.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353198.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353199.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353202.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353203.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353204.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353583.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353782.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353788.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353789.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353790.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353797.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353798.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41353799.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354283.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354398.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354403.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354404.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354405.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354411.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354412.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41354413.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41356430.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357236.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357241.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357242.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357243.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357247.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357248.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41357249.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41358842.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41358999.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359014.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359015.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359016.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359022.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359023.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41359024.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41360143.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361137.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361138.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361139.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361168.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361198.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361199.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41361200.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362090.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362308.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362309.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362310.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362351.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362460.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362461.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41362462.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41363904.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364310.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364311.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364312.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364378.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364400.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364401.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364402.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41364889.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372403.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372404.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372408.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372409.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372429.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41372454.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373630.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373631.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373650.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373651.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373708.json\n",
      "/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_41373784.json\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Get the current time\n",
    "now = datetime.now()\n",
    "\n",
    "# Calculate the time 24 hours ago from the current time\n",
    "twenty_four_hours_ago = now  # - timedelta(hours=24)\n",
    "\n",
    "# Pattern to match the files with varying numbers in the file path\n",
    "file_pattern1 = \"/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/gemma_7b_it_rewrites_*.json\"\n",
    "file_pattern2 = \"/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/chatgpt/gemma_7b_it_rewrites_*.json\"\n",
    "\n",
    "# Use glob to find all file paths that match the patterns\n",
    "file_paths1 = glob.glob(file_pattern1)\n",
    "file_paths2 = glob.glob(file_pattern2)\n",
    "file_paths = file_paths1 + file_paths2\n",
    "\n",
    "# Filter files that were modified within the last 24 hours\n",
    "# recent_file_paths = [\n",
    "#     file\n",
    "#     for file in file_paths\n",
    "#     if datetime.fromtimestamp(os.path.getmtime(file)) < twenty_four_hours_ago\n",
    "# ]\n",
    "\n",
    "# Output the list of recent file paths\n",
    "print(\"Files not modified in the last 24 hours:\")\n",
    "for file_path in file_paths:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "import re\n",
    "\n",
    "# Initialize an empty list to store the extracted entries\n",
    "entries = []\n",
    "\n",
    "# Iterate over the recent file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'delimitter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/notebooks/02-dataset-generation-for-instruction-tuning.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/gemini_categorized_prompts/prompts.csv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     delimitter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\u001b[39m.\u001b[39mset_index(\u001b[39m\"\u001b[39m\u001b[39mPrompt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m file_path \u001b[39min\u001b[39;00m file_paths:\n\u001b[1;32m     10\u001b[0m     \u001b[39m# Open the JSON file and load its contents\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file_path, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n",
      "\u001b[0;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'delimitter'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/gemini_categorized_prompts/prompts.csv\",\n",
    "    delimitter=\";\",\n",
    ").set_index(\"Prompt\")\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # Open the JSON file and load its contents\n",
    "    with open(file_path, \"r\") as file:\n",
    "        file_contents = file.read()\n",
    "        entries_raw = re.findall(r\"\\{.*?\\}\", file_contents, re.DOTALL)\n",
    "        for entry_raw in entries_raw:\n",
    "            try:\n",
    "                entry = json.loads(entry_raw)\n",
    "\n",
    "                if isinstance(entry[\"rewrite_prompt\"], float):\n",
    "                    continue\n",
    "\n",
    "                patterns = [\n",
    "                    r\"^.*?[hH]ere is.*?\\n\\n\",\n",
    "                    r\"^.*?[hH]ere \\'s.*?\\n\\n\",\n",
    "                    r\"^.*?[Ss]ure, here*?\\n\\n\",\n",
    "                ]\n",
    "\n",
    "                filtered = entry[\"rewritten_text\"]\n",
    "                for pattern in patterns:\n",
    "                    filtered = re.sub(pattern, \"\", filtered, flags=re.DOTALL)\n",
    "\n",
    "                extracted_entry = {\n",
    "                    \"rewrite_prompt\": entry[\"rewrite_prompt\"],\n",
    "                    \"original_text\": entry[\"original_text\"],\n",
    "                    \"rewritten_text\": str(filtered),\n",
    "                    \"category\": df.loc[entry[\"rewrite_prompt\"], \"Category\"],\n",
    "                }\n",
    "                entries.append(extracted_entry)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Infuse the text with elements of magical realism or fabulism, blurring the boundaries between reality and fantasy to create a sense of wonder and enchantment.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_llm/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3792\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:219\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:227\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:119\u001b[0m, in \u001b[0;36mpandas._libs.index._unpack_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Infuse the text with elements of magical realism or fabulism, blurring the boundaries between reality and fantasy to create a sense of wonder and enchantment.'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/notebooks/02-dataset-generation-for-instruction-tuning.py:35\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[39mfor\u001b[39;00m pattern \u001b[39min\u001b[39;00m patterns:\n\u001b[1;32m     29\u001b[0m         filtered \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(pattern, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, filtered, flags\u001b[39m=\u001b[39mre\u001b[39m.\u001b[39mDOTALL)\n\u001b[1;32m     31\u001b[0m     extracted_entry \u001b[39m=\u001b[39m {\n\u001b[1;32m     32\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrewrite_prompt\u001b[39m\u001b[39m\"\u001b[39m: entry[\u001b[39m\"\u001b[39m\u001b[39mrewrite_prompt\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     33\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39moriginal_text\u001b[39m\u001b[39m\"\u001b[39m: entry[\u001b[39m\"\u001b[39m\u001b[39moriginal_text\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     34\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrewritten_text\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mstr\u001b[39m(filtered),\n\u001b[0;32m---> 35\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m\"\u001b[39m: df\u001b[39m.\u001b[39mloc[entry[\u001b[39m\"\u001b[39m\u001b[39mrewrite_prompt\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mCategory\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     36\u001b[0m     }\n\u001b[1;32m     37\u001b[0m     entries\u001b[39m.\u001b[39mappend(extracted_entry)\n\u001b[1;32m     39\u001b[0m \u001b[39mexcept\u001b[39;00m json\u001b[39m.\u001b[39mJSONDecodeError:\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_llm/lib/python3.11/site-packages/pandas/core/indexing.py:1147\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1146\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1148\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_llm/lib/python3.11/site-packages/pandas/core/indexing.py:1330\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1328\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1329\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[0;32m-> 1330\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_lowerdim(tup)\n\u001b[1;32m   1332\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[1;32m   1333\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_llm/lib/python3.11/site-packages/pandas/core/indexing.py:1039\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[39mfor\u001b[39;00m i, key \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tup):\n\u001b[1;32m   1036\u001b[0m     \u001b[39mif\u001b[39;00m is_label_like(key):\n\u001b[1;32m   1037\u001b[0m         \u001b[39m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m         \u001b[39m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m         section \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_axis(key, axis\u001b[39m=\u001b[39mi)\n\u001b[1;32m   1041\u001b[0m         \u001b[39m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m         \u001b[39m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m         \u001b[39m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m         \u001b[39mif\u001b[39;00m section\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim:\n\u001b[1;32m   1045\u001b[0m             \u001b[39m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m             \u001b[39m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_llm/lib/python3.11/site-packages/pandas/core/indexing.py:1393\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1393\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_label(key, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_llm/lib/python3.11/site-packages/pandas/core/indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1342\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1343\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39mxs(label, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_llm/lib/python3.11/site-packages/pandas/core/generic.py:4236\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4234\u001b[0m             new_index \u001b[39m=\u001b[39m index[loc]\n\u001b[1;32m   4235\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4236\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39mget_loc(key)\n\u001b[1;32m   4238\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   4239\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[0;32m~/miniconda3/envs/kaggle_llm/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Infuse the text with elements of magical realism or fabulism, blurring the boundaries between reality and fantasy to create a sense of wonder and enchantment.'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/scratch/yousefi.m/projects/kaggle_llm_prompt_recovery/data/interim/gemini_categorized_prompts/prompts.csv\",\n",
    "    delimiter=\";\",\n",
    ").set_index(\"Prompt\")\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # Open the JSON file and load its contents\n",
    "    with open(file_path, \"r\") as file:\n",
    "        file_contents = file.read()\n",
    "        entries_raw = re.findall(r\"\\{.*?\\}\", file_contents, re.DOTALL)\n",
    "        for entry_raw in entries_raw:\n",
    "            try:\n",
    "                entry = json.loads(entry_raw)\n",
    "\n",
    "                if isinstance(entry[\"rewrite_prompt\"], float):\n",
    "                    continue\n",
    "\n",
    "                patterns = [\n",
    "                    r\"^.*?[hH]ere is.*?\\n\\n\",\n",
    "                    r\"^.*?[hH]ere \\'s.*?\\n\\n\",\n",
    "                    r\"^.*?[Ss]ure, here*?\\n\\n\",\n",
    "                ]\n",
    "\n",
    "                filtered = entry[\"rewritten_text\"]\n",
    "                for pattern in patterns:\n",
    "                    filtered = re.sub(pattern, \"\", filtered, flags=re.DOTALL)\n",
    "\n",
    "                extracted_entry = {\n",
    "                    \"rewrite_prompt\": entry[\"rewrite_prompt\"],\n",
    "                    \"original_text\": entry[\"original_text\"],\n",
    "                    \"rewritten_text\": str(filtered),\n",
    "                    \"category\": df.loc[entry[\"rewrite_prompt\"], \"Category\"],\n",
    "                }\n",
    "                entries.append(extracted_entry)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prompt</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Condense this into a single tweet.</th>\n",
       "      <td>Brevity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reduce this text to a maximum of 50 words.</th>\n",
       "      <td>Brevity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rewrite this in the style of a haiku.</th>\n",
       "      <td>Brevity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summarize this text in a 10-word elevator pitch.</th>\n",
       "      <td>Brevity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shorten this to its essential core, removing unnecessary details.</th>\n",
       "      <td>Brevity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rephrase the text as a collection of motivational quotes.</th>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identify real-world companies or organizations relevant to the text's topic.</th>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Repurpose the text as instructions for a DIY craft or project.</th>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summarize the text by focusing solely on the colors mentioned.</th>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retell the main events of this text from the opposite point of view.</th>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1507 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Category\n",
       "Prompt                                                           \n",
       "Condense this into a single tweet.                        Brevity\n",
       "Reduce this text to a maximum of 50 words.                Brevity\n",
       "Rewrite this in the style of a haiku.                     Brevity\n",
       "Summarize this text in a 10-word elevator pitch.          Brevity\n",
       "Shorten this to its essential core, removing un...        Brevity\n",
       "...                                                           ...\n",
       "Rephrase the text as a collection of motivation...  Summarization\n",
       "Identify real-world companies or organizations ...  Summarization\n",
       "Repurpose the text as instructions for a DIY cr...  Summarization\n",
       "Summarize the text by focusing solely on the co...  Summarization\n",
       "Retell the main events of this text from the op...  Summarization\n",
       "\n",
       "[1507 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
